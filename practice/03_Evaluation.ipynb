{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 초기 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "ragas_Evaluation_test1\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"ragas_Evaluation_test1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-teddynote 0.5.1 requires langchain>=0.3.27, but you have langchain 0.2.17 which is incompatible.\n",
      "langchain-teddynote 0.5.1 requires langchain-openai>=0.3.30, but you have langchain-openai 0.1.25 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU ragas==0.1.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ragas\n",
      "Version: 0.1.16\n",
      "Summary: \n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: \n",
      "Location: c:\\anaconda3\\envs\\final_pj\\Lib\\site-packages\n",
      "Requires: appdirs, datasets, langchain, langchain-community, langchain-core, langchain-openai, nest-asyncio, numpy, openai, pysbd, tiktoken\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "import json\n",
    "\n",
    "loader = JSONLoader('./gmp_chunks.jsonl', jq_schema='.', json_lines=True, text_content=False)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "docs = []\n",
    "\n",
    "with open('./gmp_chunks.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        docs.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c-0000',\n",
       "  'doc_id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c',\n",
       "  'source_path': 'temp_extract/raw/EU/0646aa1d61_annex 15 qualification and validation 2015 final.pdf',\n",
       "  'title': '0646aa1d61_annex 15 qualification and validation 2015 final',\n",
       "  'jurisdiction': 'EU',\n",
       "  'doc_date': '2015',\n",
       "  'doc_version': None,\n",
       "  'section_id': None,\n",
       "  'section_title': None,\n",
       "  'page_start': 1,\n",
       "  'page_end': 1,\n",
       "  'chunk_index': 0,\n",
       "  'text': 'EU GMP Guide, Annex 15. Qualification and Validation GE010b\\n \\ngggmmmpppeeeyyyeee \\nwww.gmpeye.co.kr \\n1 \\n \\nEUROPEAN COMMISSION \\nDIRECTORATE-GENERAL FOR HEALTH AND FOOD SAFETY \\n \\n2015년 3월 30일, 브뤼셀 \\n \\n \\nEudraLex \\n \\nVolume 4 \\nEU Guidelines for Good Manufacturing Practice \\nfor Medicinal Products for Human and Veterinary Use \\n \\nAnnex 15: Qualification and Validation \\n \\nLegal basis for publishing the detailed guidelines: Article 47 of Directive 2001/83/EC on \\nthe Community code relating to medicinal products for human use a n d A r t i c l e 5 1 o f \\nDirective 2001/82/EC on the Community code relating to veterinary medicinal products. This \\ndocument provides guidance for the interpretation of the princi ples and guidelines of good \\nmanufacturing practice (GMP) for medicinal products as laid dow n in Directive 2003/94/EC \\nfor medicinal products for human use and Directive 91/412/EEC for veterinary use. \\n세부 가이드라인 발행의 법적 근거 : 사람 의약품 관련 EC 법률에 관한 디렉티브'},\n",
       " {'id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c-0001',\n",
       "  'doc_id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c',\n",
       "  'source_path': 'temp_extract/raw/EU/0646aa1d61_annex 15 qualification and validation 2015 final.pdf',\n",
       "  'title': '0646aa1d61_annex 15 qualification and validation 2015 final',\n",
       "  'jurisdiction': 'EU',\n",
       "  'doc_date': '2015',\n",
       "  'doc_version': None,\n",
       "  'section_id': None,\n",
       "  'section_title': None,\n",
       "  'page_start': 1,\n",
       "  'page_end': 2,\n",
       "  'chunk_index': 1,\n",
       "  'text': '세부 가이드라인 발행의 법적 근거 : 사람 의약품 관련 EC 법률에 관한 디렉티브 \\n2001/83/EC의 제47조와 동물 의약품 관련 EC 법률에 관한 디렉티브 2001/82/EC의 제51조. \\n이 문서는 사람 의약품에 대한 디렉티브 2003/94/EC와 동물 의약품에 대한 디렉티브 \\n91/412/EEC에 제시된 의약품 GMP의 원칙과 가이드라인의 해석과 지침을 제공한다. \\n \\nStatus of the document: Revision \\n문서 상태: 개정 \\n \\nReasons for changes: Since Annex 15 was published in 2001 the manufacturing and \\nregulatory environment has changed significantly and an update is required to this Annex to \\nreflect this changed environment. This revision to Annex 15 tak es into account changes to \\nother sections of the EudraLex, Volume 4, Part I, relationship to Part II, Annex 11, ICH Q8, \\nQ9, Q10 and Q11, QWP guidance on process validation, and change s in manufacturing \\ntechnology. \\n변경 이유: 2001년에 부록 15가 발행된 이후로, 제조 환경과 규제 환경이 크게 변했고, 이와'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 로드된 문서의 각 metadata에 filename 속성 추가\n",
    "    - filename속성은 Test Datasets 생성 프로세스에서 활용됨\n",
    "    - 동일한 문서에 속한 청크를 식별하는 데 사용 됨 (source와 같은 역할)\n",
    "    - source의 내용을 filename속성에 복사해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 Document객체의 metadata에 filename속성 추가\n",
    "for doc in docs:\n",
    "    doc.metadata['filename'] = doc.metadata['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 데이터셋 생성\n",
    "- Q&A dataset 종류\n",
    "    - simple: 단순 질의응답 데이터셋\n",
    "    - reasioning: 추론 능력을 확인할 수 있는 데이터셋\n",
    "    - multi_context: 여러 문맥을 고려하여 답 생성하는 데이터셋 \n",
    "    - conditional: 조건부 질의 응답 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\final_pj\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, conditional\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.extractor import KeyphraseExtractor\n",
    "from ragas.testset.docstore import InMemoryDocumentStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 데이터셋 생성기 생성 (llm으로 데이터셋/질문 생성)\n",
    "generator_llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 데이터셋 비평기 생성 (llm으로 질문이 적합한 질문인지 평가)\n",
    "critic_llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 임베딩 모델 객체 생성\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 메모리 객체 생성 준비 (InMemory객체 옵션에 필요한 객체 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter 생성\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=550,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "\n",
    "# ragas와 호환되는 llm 생성\n",
    "# Lanchain의 ChatOpenAI 모델을 LangchainLLMWrapper로 감싸 RAGAS와 호환되도록 함\n",
    "langchain_llm = LangchainLLMWrapper(ChatOpenAI(model='gpt-4o-mini'))\n",
    "\n",
    "# 문서에서 주요 구문(KeyPhrase)를 먼저 뽑기 위한 객체 생성(ragas와 호환되는 llm 사용)\n",
    "# 즉, 문서의 주요 구문에서 질문과 답변을 뽑아냄\n",
    "keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)\n",
    "\n",
    "# ragas와 호환되는 embeddings 객체 생성\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "# InMemoryDocumentStore 객체 생성 (key phrase를 메모리에 올리는 역할)\n",
    "docstore = InMemoryDocumentStore(\n",
    "    splitter=splitter,\n",
    "    embeddings=ragas_embeddings,\n",
    "    extractor=keyphrase_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. TestSet 생성해주는 생성기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    ragas_embeddings,\n",
    "    docstore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 질의응답 유형별 분포 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 유형별 분포 설정\n",
    "# 질문을 10개 생성할 경우 각각 4개, 2개, 2개, 2개씩 생성\n",
    "distributions = {simple: 0.4, reasoning: 0.2, multi_context: 0.2, conditional: 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU GMP Guide, Annex 15. Qualification and Validation GE010b\n",
      " \n",
      "gggmmmpppeeeyyyeee \n",
      "www.gmpeye.co.kr \n",
      "1 \n",
      " \n",
      "EUROPEAN COMMISSION \n",
      "DIRECTORATE-GENERAL FOR HEALTH AND FOOD SAFETY \n",
      " \n",
      "2015년 3월 30일, 브뤼셀 \n",
      " \n",
      " \n",
      "EudraLex \n",
      " \n",
      "Volume 4 \n",
      "EU Guidelines for Good Manufacturing Practice \n",
      "for Medicinal Products for Human and Veterinary Use \n",
      " \n",
      "Annex 15: Qualification and Validation \n",
      " \n",
      "Legal basis for publishing the detailed guidelines: Article 47 of Directive 2001/83/EC on \n",
      "the Community code relating to medicinal products for human use a n d A r t i c l e 5 1 o f \n",
      "Directive 2001/82/EC on the Community code relating to veterinary medicinal products. This \n",
      "document provides guidance for the interpretation of the princi ples and guidelines of good \n",
      "manufacturing practice (GMP) for medicinal products as laid dow n in Directive 2003/94/EC \n",
      "for medicinal products for human use and Directive 91/412/EEC for veterinary use. \n",
      "세부 가이드라인 발행의 법적 근거 : 사람 의약품 관련 EC 법률에 관한 디렉티브\n",
      "{'id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c-0000', 'doc_id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c', 'source_path': 'temp_extract/raw/EU/0646aa1d61_annex 15 qualification and validation 2015 final.pdf', 'title': '0646aa1d61_annex 15 qualification and validation 2015 final', 'jurisdiction': 'EU', 'doc_date': '2015', 'doc_version': None, 'section_id': None, 'section_title': None, 'page_start': 1, 'page_end': 1, 'chunk_index': 0}\n",
      "page_content='EU GMP Guide, Annex 15. Qualification and Validation GE010b\n",
      " \n",
      "gggmmmpppeeeyyyeee \n",
      "www.gmpeye.co.kr \n",
      "1 \n",
      " \n",
      "EUROPEAN COMMISSION \n",
      "DIRECTORATE-GENERAL FOR HEALTH AND FOOD SAFETY \n",
      " \n",
      "2015년 3월 30일, 브뤼셀 \n",
      " \n",
      " \n",
      "EudraLex \n",
      " \n",
      "Volume 4 \n",
      "EU Guidelines for Good Manufacturing Practice \n",
      "for Medicinal Products for Human and Veterinary Use \n",
      " \n",
      "Annex 15: Qualification and Validation \n",
      " \n",
      "Legal basis for publishing the detailed guidelines: Article 47 of Directive 2001/83/EC on \n",
      "the Community code relating to medicinal products for human use a n d A r t i c l e 5 1 o f \n",
      "Directive 2001/82/EC on the Community code relating to veterinary medicinal products. This \n",
      "document provides guidance for the interpretation of the princi ples and guidelines of good \n",
      "manufacturing practice (GMP) for medicinal products as laid dow n in Directive 2003/94/EC \n",
      "for medicinal products for human use and Directive 91/412/EEC for veterinary use. \n",
      "세부 가이드라인 발행의 법적 근거 : 사람 의약품 관련 EC 법률에 관한 디렉티브' metadata={'id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c-0000', 'doc_id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c', 'source_path': 'temp_extract/raw/EU/0646aa1d61_annex 15 qualification and validation 2015 final.pdf', 'title': '0646aa1d61_annex 15 qualification and validation 2015 final', 'jurisdiction': 'EU', 'doc_date': '2015', 'doc_version': None, 'section_id': None, 'section_title': None, 'page_start': 1, 'page_end': 1, 'chunk_index': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "documents = []\n",
    "for d in docs:\n",
    "    # 딕셔너리의 'text' 값을 문서의 page_content로 설정\n",
    "    page_content = d.get('text', '')\n",
    "    \n",
    "    # 'text'를 제외한 나머지는 metadata로 설정\n",
    "    metadata = {k: v for k, v in d.items() if k != 'text'}\n",
    "    \n",
    "    # Document 객체 생성 및 리스트에 추가\n",
    "    doc = Document(page_content=page_content, metadata=metadata)\n",
    "    documents.append(doc)\n",
    "\n",
    "# 이제 `page_content` 속성에 정상적으로 접근할 수 있습니다.\n",
    "print(documents[0].page_content)\n",
    "# # 출력: 첫 번째 텍스트 덩어리입니다.\n",
    "\n",
    "print(documents[0].metadata)\n",
    "# 출력: {'chunk_id': 1, 'source': 'file.jsonl'}\n",
    "\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.2.16 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (2.0.43)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (3.12.15)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (0.2.43)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (2.11.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (2.32.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain==0.2.16) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (1.20.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain==0.2.16) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain==0.2.16) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain==0.2.16) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain==0.2.16) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from pydantic<3,>=1->langchain==0.2.16) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from pydantic<3,>=1->langchain==0.2.16) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from pydantic<3,>=1->langchain==0.2.16) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from requests<3,>=2->langchain==0.2.16) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from requests<3,>=2->langchain==0.2.16) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.16) (3.2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\anaconda3\\envs\\final_pj\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain (c:\\anaconda3\\envs\\final_pj\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain (c:\\anaconda3\\envs\\final_pj\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.2.16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.2.16\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\anaconda3\\envs\\final_pj\\Lib\\site-packages\n",
      "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-community, langchain-teddynote, ragas\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.metadata['filename'] = doc.metadata['source_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c-0000',\n",
       " 'doc_id': '0646aa1d61_annex_15_qualification_and_validation_2-2b20c947f12c',\n",
       " 'source_path': 'temp_extract/raw/EU/0646aa1d61_annex 15 qualification and validation 2015 final.pdf',\n",
       " 'title': '0646aa1d61_annex 15 qualification and validation 2015 final',\n",
       " 'jurisdiction': 'EU',\n",
       " 'doc_date': '2015',\n",
       " 'doc_version': None,\n",
       " 'section_id': None,\n",
       " 'section_title': None,\n",
       " 'page_start': 1,\n",
       " 'page_end': 1,\n",
       " 'chunk_index': 0,\n",
       " 'filename': 'temp_extract/raw/EU/0646aa1d61_annex 15 qualification and validation 2015 final.pdf'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nest-asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   0%|          | 0/10 [00:00<?, ?it/s]                [ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 1, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Cleaning verification', 'Chemical analysis', 'Residues of previous product']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['EU GMP Guide', 'Annex 15', 'Ongoing process verification', 'Traditional approach', 'Process validation']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['EU GMP Guide', 'Annex 15', 'Ongoing process verification', 'Traditional approach', 'Process validation']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Cleaning verification', 'Chemical analysis', 'Residues of previous product']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Control of risks to quality', 'ICH Q9', 'Simulated agents', 'Physical and chemical characteristics', 'State of control']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 2, 'score': 1.25}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 0 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 1, 'score': 1.0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 0 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['EU GMP Guide', 'Annex 15', 'Ongoing process verification', 'Traditional approach', 'Process validation']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 1, 'score': 1.0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 0 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Control of risks to quality', 'ICH Q9', 'Simulated agents', 'Physical and chemical characteristics', 'State of control']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key applications of Annex 15 in the context of process validation?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What does the EU GMP Guide state about ongoing process verification during lifecycle?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the physical and chemical characteristics that a material should approximate in validation processes?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Medicinal products for human use', 'Directive 91/412/EEC', 'Veterinary use', 'GMP guidelines', 'Cross-contamination prevention']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of analyzing the residues of the previous product in the cleaning verification process?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of the traditional approach in the context of process validation according to the EU GMP Guide?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 1, 'score': 1.0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 0 times\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of control of risks to quality across the lifecycle?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 2, 'score': 1.25}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 0 times\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the purpose of chemical analysis in the context of cleaning verification?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What regulations govern veterinary use in the context of medicinal products?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 2, 'score': 1.25}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 0 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Qualification and validation', 'Planning and organizing', 'Life cycle considerations', 'Trained personnel', 'Approved procedures']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key considerations for qualification and validation activities in facilities and equipment?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['EudraLex Volume 4 Part I', 'Manual cleaning of equipment', 'Effectiveness confirmation', 'Change control', 'Product specifications']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key applications of Annex 15 specifically in the context of process validation. It is clear in its intent, specifying both the subject (Annex 15) and the area of interest (process validation). However, the term 'Annex 15' may not be universally understood without additional context, as it could refer to different documents or regulations in various fields. To improve clarity and answerability, the question could specify which Annex 15 is being referred to (e.g., from which regulatory body or document) and provide a brief context about its relevance to process validation.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of change control as mentioned in EudraLex, Volume 4, Part I?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key applications of Annex 15 from the EU GMP Guide in the context of process validation?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the physical and chemical characteristics that a material should approximate during validation processes. It is relatively clear in its intent, seeking specific information about characteristics relevant to validation. However, it lacks specificity regarding the type of materials or validation processes being referred to, which could lead to ambiguity. To improve clarity and answerability, the question could specify the context (e.g., materials for construction, pharmaceuticals, etc.) or the specific validation processes (e.g., quality control, regulatory compliance) to provide a more focused inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the content of the EU GMP Guide regarding ongoing process verification during the lifecycle. It is specific in its focus on the EU GMP Guide and the particular aspect of ongoing process verification. However, it assumes familiarity with the EU GMP Guide without providing any context or details about what ongoing process verification entails. To improve clarity and answerability, the question could briefly define ongoing process verification or specify the particular section or aspect of the guide being referenced. This would help ensure that the question is understandable to those who may not have direct access to the guide.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of analyzing residues from a previous product in the cleaning verification process. It is specific and has a clear intent, focusing on the importance of a particular aspect of cleaning verification. However, it could benefit from a bit more context regarding what type of residues are being referred to and the specific cleaning verification process in question. Providing a brief description of the cleaning verification process or the types of products involved could enhance clarity and answerability for those unfamiliar with the topic.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the physical and chemical characteristics that a material should approximate in validation processes for pharmaceuticals?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What does the EU GMP Guide, specifically in paragraphs 5.28-5.32, state about the concept of ongoing process verification during the lifecycle of a product?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the key considerations for qualification and validation activities specifically related to facilities and equipment. It is clear in its intent, specifying the focus on qualification and validation activities, which are common in regulated industries such as pharmaceuticals and biotechnology. However, the question could be improved by providing more context or specifying the type of facilities and equipment in question, as these considerations can vary significantly across different sectors. To enhance clarity and answerability, the question could specify whether it refers to manufacturing facilities, laboratory equipment, or another context.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What are the key considerations for qualification and validation activities in facilities and equipment?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of the traditional approach in process validation as outlined in the EU GMP Guide. It specifies the context (EU GMP Guide) and the topic (traditional approach in process validation), making the intent clear. However, the term 'traditional approach' could be interpreted in various ways without further clarification. To improve clarity and answerability, the question could specify what aspects of the traditional approach are being referred to (e.g., specific methodologies, historical context) or what particular significance is being sought (e.g., advantages, limitations, comparisons to modern approaches).\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the purpose of chemical analysis specifically in the context of cleaning verification. It is clear and specific, indicating the type of analysis (chemical) and the context (cleaning verification), which allows for a direct and relevant response. The intent is unambiguous, making it understandable and answerable based on the details provided. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What is the purpose of chemical analysis in the context of cleaning verification?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the key applications of Annex 15 from the EU GMP Guide specifically in the context of process validation. It is clear in its intent, specifying both the document (Annex 15) and the area of interest (process validation). However, it assumes that the reader has prior knowledge of what Annex 15 entails and its relevance to process validation, which may not be universally understood. To improve clarity and answerability, the question could briefly define what Annex 15 covers or its significance in the EU GMP Guide, or it could specify particular aspects of process validation that are of interest.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What are the key applications of Annex 15 from the EU GMP Guide in the context of process validation?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of controlling risks to quality throughout a lifecycle, which is a clear and specific inquiry. However, it lacks context regarding what type of lifecycle is being referred to (e.g., product development, project management, software development) and what specific risks or quality aspects are of interest. To improve clarity and answerability, the question could specify the context of the lifecycle and the types of risks or quality measures being considered. For example, it could be rephrased as, 'What is the significance of controlling risks to product quality in the product development lifecycle?' This would provide a clearer framework for the answer.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of change control as mentioned in EudraLex, Volume 4, Part I. While it specifies the topic of interest (change control) and the source (EudraLex, Volume 4, Part I), it assumes familiarity with this specific document without providing any context or details about what EudraLex entails. This reliance on external references makes the question less independent and potentially unclear for those who are not familiar with EudraLex. To improve clarity and answerability, the question could briefly explain what EudraLex is or provide a summary of the relevant section regarding change control, allowing for a more informed response.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What essential factors must be addressed by trained personnel when planning qualification and validation activities for facilities and equipment, considering both lifecycle and regulatory guidelines?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the regulations governing veterinary use in the context of medicinal products. It is specific and clear in its intent, focusing on regulations related to veterinary medicine. However, it could benefit from additional context regarding the geographical region or specific type of medicinal products being referred to, as regulations can vary significantly by country or type of product (e.g., pharmaceuticals, vaccines). To improve clarity and answerability, the question could specify the country or region of interest or the type of medicinal products being considered.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of controlling risks to product quality in the product development lifecycle?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What critical roles does Annex 15 of the EU GMP Guide play in the validation processes, particularly in relation to historical batch data and ongoing process verification?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating:  10%|█         | 1/10 [00:12<01:53, 12.57s/it][ragas.testset.evolutions.INFO] rewritten question: \"What regulations govern veterinary use of medicinal products in the European Union?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of change control in the context of pharmaceutical regulations as outlined in EudraLex, Volume 4, Part I?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the physical and chemical characteristics that materials should approximate during validation processes for pharmaceuticals. It is specific in its focus on materials used in pharmaceuticals and seeks to understand the relevant characteristics for validation. However, the question could benefit from being more explicit about what types of validation processes are being referred to (e.g., clinical trials, quality control) and what specific characteristics are of interest (e.g., solubility, stability, purity). Providing examples or specifying the context of the validation processes would enhance clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What are the physical and chemical characteristics that a material should approximate in validation processes for pharmaceuticals?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating:  20%|██        | 2/10 [00:13<00:43,  5.49s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for specific information from the EU GMP Guide, focusing on paragraphs 5.28-5.32 regarding ongoing process verification during a product's lifecycle. While it clearly specifies the document and the sections of interest, it relies on access to the EU GMP Guide without providing any context or content from those paragraphs. This makes the question unclear for those who do not have access to the document. To improve clarity and answerability, the question could either summarize the key points of those paragraphs or ask for a general explanation of ongoing process verification without referencing specific sections of the guide.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 1, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Concurrent validation', 'Justification', 'VMP documentation', 'Approved by authorised personnel']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and seeks to identify essential factors that trained personnel must consider when planning qualification and validation activities for facilities and equipment, with a focus on lifecycle and regulatory guidelines. It is clear in its intent and does not rely on external references, making it understandable and answerable based on the details provided. However, it could be improved by specifying the type of facilities and equipment in question, as well as the relevant regulatory guidelines, to enhance clarity and focus. Overall, the question is well-structured and meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question clearly asks about the role of chemical analysis in confirming cleaning effectiveness after production. It is specific and independent, as it does not rely on external references or additional context to be understood. The intent is clear, seeking information on the relationship between chemical analysis and cleaning effectiveness. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking about the regulations that govern the veterinary use of medicinal products specifically within the European Union. It does not rely on external references or additional context, making it independent and self-contained. The intent is also clear, as it seeks information about regulatory frameworks. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of controlling risks to product quality within the product development lifecycle. It is clear in its intent, focusing on the importance of risk management in relation to product quality. The question is independent and does not rely on external references or specific documents, making it understandable and answerable based on general knowledge of product development processes. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"What is the significance of controlling risks to product quality in the product development lifecycle?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What role does chemical analysis play in confirming cleaning effectiveness after production?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What key factors should trained staff consider for facility and equipment validation?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What must be done to justify the decision to carry out concurrent validation?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of change control within the framework of pharmaceutical regulations, specifically referencing EudraLex, Volume 4, Part I. While it specifies the topic and context, it assumes familiarity with EudraLex and its contents, which may not be accessible to all audiences. To improve clarity and answerability, the question could briefly explain what EudraLex, Volume 4, Part I entails or provide a summary of its relevance to change control. This would help those unfamiliar with the document understand the context better.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the critical roles of Annex 15 of the EU GMP Guide in validation processes, specifically regarding historical batch data and ongoing process verification. It is clear in its intent and specifies the topic of interest (Annex 15, EU GMP Guide) along with the aspects of validation processes it seeks to explore. However, the question assumes familiarity with the EU GMP Guide and its Annex 15, which may not be accessible to all audiences. To improve clarity and answerability, it could be beneficial to provide a brief context or definition of Annex 15 and its relevance to validation processes, or to specify what particular roles or aspects of validation are of interest.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the characteristics required for a simulated agent to be effective in pharmaceutical validation. It is specific and independent, as it does not rely on external references or additional context. The intent is clear, seeking information about the necessary traits or features of a simulated agent in this specific application. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Batch segregation', 'Stock rotation', 'Checks on yields', 'Reconciliation of quantities', 'Discrepancies outside acceptable limits']\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What key roles does Annex 15 of the EU GMP Guide have in validation, especially regarding historical batch data and process verification?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions focus on the role of chemical analysis in verifying cleaning processes, addressing similar constraints and requirements regarding cleaning effectiveness. They also share comparable depth and breadth in their inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What characteristics must a simulated agent match for effective pharmaceutical validation?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The regulations governing veterinary use of medicinal products in the European Union include Directive 91/412/EEC.', 'verdict': 1}\n",
      "Generating:  30%|███       | 3/10 [00:17<00:36,  5.14s/it][ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions address the topic of qualification and validation in facilities and equipment, but they differ in focus. The first question is broader, encompassing all key considerations, while the second specifically emphasizes trained staff and their factors, indicating a difference in depth and breadth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 2, 'score': 1.25}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the necessary actions or considerations required to justify the decision for concurrent validation. It is specific and has a clear intent, focusing on the justification process for a particular validation method. However, it could benefit from additional context regarding what type of concurrent validation is being referred to (e.g., in a specific field like software development, clinical trials, etc.) to enhance clarity and ensure that the answer is relevant to the intended audience. Including such context would make the question more self-contained and easier to answer comprehensively.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"What must be done to justify the decision to carry out concurrent validation?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the specific physical and chemical characteristics required for materials in pharmaceutical validation, while the second question addresses the traits of a sim agent, which is a different concept. This leads to differing constraints and depths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What measures should be taken to ensure there are no discrepancies outside acceptable limits?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the applications of Annex 15 in process validation, while the second question emphasizes the roles of Annex 15 in validation, particularly concerning historical batch data and process verification. This indicates a difference in focus and depth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['EU GMP Guide', 'Annex 15', 'Qualification and Validation', 'Installation qualification (IQ)', 'Manufacturing site equipment']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the impact of effective risk control on product quality during the product development lifecycle, particularly in the context of regulatory scrutiny. It is specific in its focus on risk control and product quality, and it clearly indicates the context of regulatory scrutiny. However, the question could be improved by clarifying what aspects of product quality are being considered (e.g., reliability, safety, compliance) and how risk control is defined in this context. Additionally, it could specify the type of products or industries being referred to, as this could influence the answer. Overall, while the question is relatively clear, providing more detail would enhance its clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key requirements outlined in Annex 15 regarding installation qualification (IQ) for equipment and systems?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Trained staff should consider the life cycle of facilities, equipment, utilities, processes, and products when planning qualification and validation activities. They must also follow approved procedures and ensure that all activities are performed by suitably trained personnel.', 'verdict': 1}\n",
      "Generating:  40%|████      | 4/10 [00:21<00:27,  4.53s/it][ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating:  50%|█████     | 5/10 [00:21<00:15,  3.08s/it][ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"What impact does effective risk control have on product quality during the product development lifecycle, especially when facing regulatory scrutiny?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The context does not provide specific information about the key roles of Annex 15 of the EU GMP Guide in validation, particularly concerning historical batch data and process verification.', 'verdict': -1}\n",
      "Generating:  60%|██████    | 6/10 [00:22<00:08,  2.15s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about measures to prevent discrepancies outside acceptable limits, but it lacks specificity regarding the context or domain in which these discrepancies are being considered (e.g., quality control, financial reporting, data analysis). This ambiguity makes it difficult to provide a focused and relevant answer. To improve clarity and answerability, the question could specify the area of concern (e.g., manufacturing, finance, data integrity) and what is meant by 'acceptable limits' (e.g., regulatory standards, industry benchmarks).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What measures should be taken in the context of Good Manufacturing Practice to ensure there are no discrepancies in product yields outside acceptable limits?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the documentation needed for concurrent validation approval by authorized personnel. It is specific in its intent, focusing on the type of documentation required for a particular process (concurrent validation) and the context of approval by authorized personnel. However, it may still be somewhat unclear for those unfamiliar with the specific requirements or context of concurrent validation in a given field (e.g., clinical trials, software development). To enhance clarity and answerability, the question could specify the field or context in which concurrent validation is being discussed, as requirements may vary significantly across different domains.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the significance of risk control in the product development lifecycle, while the second question emphasizes the effects of risk control on product quality, particularly in a regulatory context. This introduces different angles of inquiry, leading to a difference in depth and breadth.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the key requirements related to installation qualification (IQ) for equipment and systems as outlined in Annex 15. It is specific in its focus on Annex 15 and the topic of installation qualification, which provides a clear intent for the answer. However, it assumes familiarity with what Annex 15 refers to without providing any context or details about it. To improve clarity and answerability for those who may not be familiar with Annex 15, the question could include a brief description of what Annex 15 pertains to (e.g., its relevance in a specific regulatory framework or industry).', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"What documentation is required to justify concurrent validation if it is to be approved by authorized personnel?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key requirements outlined in Annex 15 of the EU GMP Guide regarding installation qualification (IQ) for equipment and systems used in pharmaceutical manufacturing?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and clear in its intent, asking about measures related to Good Manufacturing Practice (GMP) to prevent discrepancies in product yields. It does not rely on external references and can be understood independently. However, it could be improved by specifying the type of products or manufacturing processes in question, as GMP can vary significantly across different industries. Adding such details would enhance clarity and allow for a more tailored response.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The context discusses quality risk management as a systematic process for assessing, controlling, communicating, and reviewing risks to quality across the lifecycle, which implies that effective risk control is essential for maintaining product quality during development, particularly under regulatory frameworks.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the justification process for concurrent validation, while the second question asks specifically about the documentation required for approval. They differ in their constraints and requirements, leading to different depths of inquiry.', 'verdict': 0}\n",
      "Generating:  70%|███████   | 7/10 [00:26<00:08,  2.92s/it][ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating:  80%|████████  | 8/10 [00:29<00:05,  2.77s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and seeks information about the key requirements for installation qualification (IQ) as outlined in Annex 15 of the EU GMP Guide. However, it assumes familiarity with the EU GMP Guide and Annex 15 without providing any context or details about what those requirements might entail. To improve clarity and answerability for a broader audience, the question could include a brief description of the EU GMP Guide or specify the type of equipment and systems being referred to. This would help those unfamiliar with the document understand the context better.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Checks on yields and reconciliation of quantities should be carried out as necessary to ensure that there are no discrepancies outside acceptable limits.', 'verdict': 1}\n",
      "Generating:  90%|█████████ | 9/10 [00:29<00:01,  1.97s/it][ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Quality risk management', 'Medicinal product lifecycle', 'GMP guidelines', 'ICH Q8, Q9, Q10, Q11', 'Risk assessment']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of GMP guidelines in the lifecycle of a medicinal product?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of GMP (Good Manufacturing Practice) guidelines in the lifecycle of a medicinal product. It is clear in its intent, specifying both the subject (GMP guidelines) and the context (lifecycle of a medicinal product). The question is independent and can be understood without needing additional context or references. Therefore, it is specific, independent, and has a clear intent.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What is the significance of GMP guidelines in the lifecycle of a medicinal product?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of GMP (Good Manufacturing Practice) guidelines in ensuring quality throughout a product's lifecycle. It is specific and has a clear intent, focusing on the relationship between GMP guidelines and product quality. However, it assumes that the reader has prior knowledge of what GMP guidelines entail and how they relate to product lifecycle management. To enhance clarity and answerability for a broader audience, the question could briefly define GMP guidelines or specify the type of products being referred to (e.g., pharmaceuticals, food products) to provide context.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What role do GMP guidelines play in ensuring quality throughout a product's lifecycle?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions address GMP guidelines in relation to medicinal products, but they focus on different aspects: one on significance in the lifecycle and the other on ensuring product quality, leading to different depths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating: 100%|██████████| 10/10 [00:44<00:00,  4.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# test dataset 객체 생성\n",
    "test_dataset = generator.generate_with_langchain_docs(\n",
    "    documents=documents,\n",
    "    test_size=10,\n",
    "    distributions=distributions,\n",
    "    with_debugging_logs=True,\n",
    "    raise_exceptions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바보야 감자야 잘가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ragas.testset.generator.TestDataset'>\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'str',\n",
       " 'contexts': 't.List[str]',\n",
       " 'ground_truth': 't.Union[str, float]',\n",
       " 'evolution_type': 'str',\n",
       " 'metadata': 't.List[dict]'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_dataset))\n",
    "print(len(test_dataset.test_data))\n",
    "test_dataset.test_data[0].__annotations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. DataFrame으로 변형\n",
    "    - question: 생성된 질문\n",
    "    - contexts: 질문의 근거가 되는 청크\n",
    "    - ground_truth: llm이 만들어낸 정답 답변\n",
    "    - evolution_type: 질의 유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the significance of analyzing the resi...</td>\n",
       "      <td>[보여 주는 증거 문서를 확립하는 활동이다. \\n \\n세척 베리피케이션(Cleani...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'id': '0646aa1d61_annex_15_qualification_and...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What regulations govern veterinary use of medi...</td>\n",
       "      <td>[manufacturing practice (GMP) for medicinal pr...</td>\n",
       "      <td>The regulations governing veterinary use of me...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'id': '0b26bc7349_eu_gmp_guide_chapter_5_pro...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of the traditional ap...</td>\n",
       "      <td>[historical batch data. \\n 과거 배치 데이터와 제조 경험을 통...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'id': '0646aa1d61_annex_15_qualification_and...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What measures should be taken in the context o...</td>\n",
       "      <td>[EU Guide to Good Manufacturing Practice for M...</td>\n",
       "      <td>Checks on yields and reconciliation of quantit...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'id': '0b26bc7349_eu_gmp_guide_chapter_5_pro...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do GMP guidelines ensure product quality?</td>\n",
       "      <td>[아니며, 활성 성분 제조업체는 이 부록을 보완적인 가이드라인으로 선택하여 활용할 ...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'id': '0646aa1d61_annex_15_qualification_and...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the significance of analyzing the resi...   \n",
       "1  What regulations govern veterinary use of medi...   \n",
       "2  What is the significance of the traditional ap...   \n",
       "3  What measures should be taken in the context o...   \n",
       "4      How do GMP guidelines ensure product quality?   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [보여 주는 증거 문서를 확립하는 활동이다. \\n \\n세척 베리피케이션(Cleani...   \n",
       "1  [manufacturing practice (GMP) for medicinal pr...   \n",
       "2  [historical batch data. \\n 과거 배치 데이터와 제조 경험을 통...   \n",
       "3  [EU Guide to Good Manufacturing Practice for M...   \n",
       "4  [아니며, 활성 성분 제조업체는 이 부록을 보완적인 가이드라인으로 선택하여 활용할 ...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The answer to given question is not present in...         simple   \n",
       "1  The regulations governing veterinary use of me...         simple   \n",
       "2  The answer to given question is not present in...         simple   \n",
       "3  Checks on yields and reconciliation of quantit...         simple   \n",
       "4  The answer to given question is not present in...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'id': '0646aa1d61_annex_15_qualification_and...          True  \n",
       "1  [{'id': '0b26bc7349_eu_gmp_guide_chapter_5_pro...          True  \n",
       "2  [{'id': '0646aa1d61_annex_15_qualification_and...          True  \n",
       "3  [{'id': '0b26bc7349_eu_gmp_guide_chapter_5_pro...          True  \n",
       "4  [{'id': '0646aa1d61_annex_15_qualification_and...          True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe으로 변형\n",
    "test_df = test_dataset.to_pandas()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to given question is not present in context'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0]['ground_truth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/ragas_test_dataset.csv', index=False) # df의 인덱스는 포함 안 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. csv 파일 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/ragas_test_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. DataFrame을 Dataset 객체로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# ragas에서 평가 시 Dataset클래스로 매핑이 돼있어야 됨\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. df의 contexts를 list 타입으로 벼환해주기\n",
    "- 겉보기엔 list처럼 보이지만 사실 str 값임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts 칼럼 타입 확인 \n",
    "print(type(df.iloc[0]['contexts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# contexts 칼럼 데이터를 list로 변환 \n",
    "def conver_to_list(example):\n",
    "    contexts = ast.literal_eval(example['contexts']) # literal_eval: 문자열을 파이썬 객체로 변환해줌 \n",
    "    return {'contexts': contexts}\n",
    "\n",
    "# map\n",
    "#   입력: Dataset의 각 행이 사용자 정의 함수에 입력으로 들어감\n",
    "#   출력: 사용자 정의함수가 적용된 새로운 Dataset이 반환됨\n",
    "test_dataset = test_dataset.map(conver_to_list) \n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타입 변환된 거 확인\n",
    "print(type(test_dataset[0]['contexts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 예제 프롬프트 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 문서 로드\n",
    "loader = PDFPlumberLoader('./data/SPRi AI Brief_10월호_산업동향_F.pdf')\n",
    "docs = loader.load()[3:-1]\n",
    "\n",
    "# 2. 문서 분할\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=550,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "# 3. 임베딩 객체 생성\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 4. vectorstore 생성 및 저장 \n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# 5. 검색기 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 6. 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "당신은 친절한 챗봇입니다. 사용자의 질문에 대답해주세요.\n",
    "사용자의 질문이 들어오면 context에 기반하여 question에 대답해주세요.\n",
    "\n",
    "#Context:\n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 7. llm 객체 생성\n",
    "model = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
    "\n",
    "# 8. chain 생성\n",
    "chain = (\n",
    "    {'context': retriever, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. batch 데이터셋 생성\n",
    "    - 다량의 질문을 한 번에 처리할 때 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataset = [question for question in test_dataset['question']]\n",
    "batch_dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 평가용 질문으로 답변 받아보기 \n",
    "    - batch 방식 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.batch(batch_dataset)\n",
    "\n",
    "# 답변\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 답변을 test_dataset의 answer 컬럼에 저장하기 (answer컬럼 새로 생성해줘야 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer 컬럼 덮어 씌우기 또는 추가\n",
    "if 'answer' in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns(['answer']).add_column('answer', result)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column('answer', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test_dataset))\n",
    "test_dataset.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1  답변 평가  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Context Recall \n",
    "    - 검색된 context가 LLM이 생성한 답변과 얼마나 일치하는지 측정 \n",
    "        - 10개의 chunks를 뽑아냈는데 10개 모두에 답변에 필요한 내용이 담겨있는 경우 \n",
    "        - 즉, ground-truth가 10개의 문서에 모두 있는 경우 성능이 좋음을 의미\n",
    "    - 0~1 사이의 값\n",
    "    - 값이 높을 수록 좋은 성능을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Context Precision\n",
    "    - 얼마나 관련성 있는 문서가 상위에 배치되었는가?\n",
    "    - 즉, ground-truth가 포함된 문서가 얼마나 상위에 배치돼있는가를 판단 \n",
    "    - 예를 들어) 답변에 필요한 문서가 3개인데 3개가 retriever로 뽑은 10개의 문서 중 상위 3위안에 들면 성능은 만점이 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Answer Relevancy\n",
    "    - 생성된 답변이 주어진 prompt에 얼마나 적절한지를 평가 \n",
    "    - 즉 생성된 답변이 원래 질문의 의도를 얼마나 잘 반영하는지를 측정 \n",
    "    - 질문의 임베딩과 생성된 답변의 임베딩의 코사인 유사도 측정\n",
    "        - 답변이 질문과 연관성이 높으면 높은 점수를 받음 \n",
    "    - 0~1사이의 값을 가지거나 코사인 유사도 특성상 수학적으로 -1~1 사이의 값을 가질 수도 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Faithfulness\n",
    "    - 생성된 답변의 사실적 일관성을 주어진 컨텍스트와 비교하여 측정하는 지표 \n",
    "    - 즉, 주어진 context에 얼마나 충실히 (정확히) 답변했는지 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result.to_pandas()\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[:, 'context_precision':'context_recall']\n",
    "# precision(1.0이 나올 경우 ground-truth가 포함된 context의 유사도가 1순위임을 의미)\n",
    "# faithfulness(사실 여부 판단)\n",
    "# answer_relevancy(prompt에따라 잘 답변 했는지 정도)\n",
    "# context_recall(검색된 context가 LLM이 생성한 답변(answer)과 얼마나 일치하는지)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_pj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
